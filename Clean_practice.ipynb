{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7054575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dependencies\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0eb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir ='C://Users/Cathy/Desktop/Data Analytics Boot Camp/Repositories/Movies/Movies-ETL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f'{file_dir}filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{file_dir}/wikipedia-movies.json', mode='r') as file:\n",
    "    wiki_movies_raw = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44050277",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wiki_movies_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a0fea-2399-4f0f-831a-f32ed908c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 records\n",
    "wiki_movies_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252ce7c-4e42-42bf-b9db-d7caa0aa6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 records\n",
    "wiki_movies_raw[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086454a8-5971-43f7-bac1-056624a0759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some records in the middle\n",
    "wiki_movies_raw[3600:3605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71dcbb-5529-4bb5-b748-82fbc01422f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
    "ratings = pd.read_csv(f'{file_dir}ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b7d6e-c3a6-4880-b543-7cbfdbb5a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22501cef-9bbe-406b-8a75-8db42d41aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef67cd7-3f0e-41f9-adb7-65c052e8dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88abc320-cd45-4288-b5ee-ceeb8ba16f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df=pd.DataFrame(wiki_movies_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739ba71-b61f-4dda-975c-3fca9e98c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73367b62-ffe4-4efc-bbf8-2f1d98ce27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a596281-1f54-4e6a-8155-93e29e797c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[expression for element in source_list if filter_expression]\n",
    "\n",
    "#wiki_movies = [movie for movie in wiki_movies_raw\n",
    " #              if ('Director' in movie or 'Directed by' in movie)\n",
    "  #                 and 'imdb_link' in movie]\n",
    "\n",
    "wiki_movies = [movie for movie in wiki_movies_raw\n",
    "               if ('Director' in movie or 'Directed by' in movie)\n",
    "                   and 'imdb_link' in movie\n",
    "                   and 'No. of episodes' not in movie]\n",
    "\n",
    "\n",
    "\n",
    "len(wiki_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afad9f7-2eb1-4526-97bc-e95c34035146",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df= pd.DataFrame(wiki_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97e1c0-c08c-4977-b82f-1c7ad0a69225",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wiki_movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553caef-48f3-4e02-ad8d-fc1a7926fedc",
   "metadata": {},
   "source": [
    "wiki_movies_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b0665-5107-4ea6-8d3f-a6b779950640",
   "metadata": {},
   "outputs": [],
   "source": [
    "square = lambda x: x * x\n",
    "square(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c76067-2d75-4437-b8cb-90fb5a6109ee",
   "metadata": {},
   "source": [
    "As an example, we could start our function off with this code:\n",
    "\n",
    "def clean_movie(movie):\n",
    "    movie_copy = dict(movie)\n",
    "However, we have another trick that's even better.\n",
    "\n",
    "Inside of the function, we can create a new local variable called movie and assign it the new copy of the parameter movie.\n",
    "\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "This way, inside of the clean_movie() function, movie will refer to the local copy. Any changes we make inside clean_movie() will now only affect the copy, so if we make a mistake, we still have the original, untouched movie to reference.\n",
    "\n",
    "To finish our skeleton of the clean_movie function, return the movie variable.\n",
    "\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44a9c9-b489-493b-96ad-463848ffe2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f4eae-8b5b-47ca-bb7f-37c06795c08d",
   "metadata": {},
   "source": [
    "Now take a look at what's going on with those languages. The first one on the list is Arabic, so let's see which movies have a value for \"Arabic.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5a329-0346-4c33-a190-baf232926519",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6943404-5de0-4065-809b-abf52fc39be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df[wiki_movies_df['Based on'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4cec6-38de-418a-9424-9c59910770cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc30dfd-f73c-4f7d-84fd-734144c77e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    alt_titles = {}\n",
    "    # combine alternate titles into one list\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune-Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "\n",
    "    # merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c598e-67b8-40be-a4b6-1a5569a9e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6aa9e2-926e-47b7-a8e9-6dce17e87006",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd79a2-f9fa-458c-bce9-a9e002479a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259b76e-f9e7-4d8b-89df-61e3cf7ee603",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "print(len(wiki_movies_df))\n",
    "wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "print(len(wiki_movies_df))\n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6445b-a6f8-4f0c-87f4-0dcaed5e3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[column,wiki_movies_df[column].isnull().sum()] for column in wiki_movies_df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3785cd-9606-43d1-b7c4-4c9a6e7adbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to keep\n",
    "[column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e27c31-c989-4fd9-a7de-b079481335df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe with keepers\n",
    "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73e93e-5cdc-4321-af2e-635ba9ec243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cffa7a-2f62-434d-810e-d512d7a540b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3d54d-1abd-4aec-81e0-bf1590bd908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e955f19-b1c7-4d1c-894b-bcf4ee44d2f3",
   "metadata": {},
   "source": [
    "Box office should be numeric.\n",
    "Budget should be numeric.\n",
    "Release date should be a date object.\n",
    "Running time should be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3597633-a06a-4bd3-b337-6b95ed44ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office = wiki_movies_df['Box office'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba5eb5-1a38-4e81-96cc-e1f0d980c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f719205-50c9-43e4-821e-48569854cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_a_string(x):\n",
    "    return type(x) != str\n",
    "box_office[box_office.map(is_not_a_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18ddb3-9b0a-4757-a372-3b9c2fc1054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update using a lambda function\n",
    "box_office[box_office.map(lambda x: type(x) != str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade5173-5deb-4256-aba6-7247f77d2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba9a29-a2a6-47f4-8d3d-750b036b0ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8605a4-a5d7-4cbb-8d08-7ee44fe6817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8331167-abdb-4ff1-8e2f-c7ad1a44b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office.str.contains(form_one, flags=re.IGNORECASE, na=False).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b82b3-b952-4fd4-bf80-5dcc290a74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "box_office.str.contains(form_two, flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd04cac-0469-4e5a-a085-395c1d7f6db5",
   "metadata": {},
   "source": [
    "These can be reused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f1fa4-d9dd-4047-a549-d24d3a08e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
    "form_two = r'\\$\\s*\\d{1,3}(?:,\\d{3})+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2d9b6-d121-4396-8508-85351ead8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
    "matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c22c3-9fdf-4243-8f85-a6b077e1dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will throw an error!\n",
    "#box_office[(not matches_form_one) and (not matches_form_two)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5808e-c225-44e3-a9f0-10d98bec13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office[~matches_form_one & ~matches_form_two]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8396832-8878-4c55-9e4b-8f7fa262dd21",
   "metadata": {},
   "source": [
    "Some values use a period as a thousands separator, not a comma.\n",
    "This is slightly more complicated, but doable. Simply change form_two to allow for either a comma or period as a thousands separator. We’d ordinarily do that by putting the comma and period inside straight brackets [,.], but the period needs to be escaped with a slash [,\\.]. The code should match the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6784850-56fd-4bac-9f11-b46cac8477b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
    "form_two = r'\\$\\s*\\d{1,3}(?:,\\d{3})+'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d4ab1-04aa-47c1-a11c-6d207c9a020a",
   "metadata": {},
   "source": [
    "Some values use a period as a thousands separator, not a comma.\n",
    "This is slightly more complicated, but doable. Simply change form_two to allow for either a comma or period as a thousands separator. We’d ordinarily do that by putting the comma and period inside straight brackets [,.], but the period needs to be escaped with a slash [,\\.]. The code should match the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ba955-90fb-49b4-88aa-39c4bc8a0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561075a3-d134-46e9-9f90-c54e684f65cf",
   "metadata": {},
   "source": [
    "The results will also match values like 1.234 billion, but we're trying to change raw numbers like $123.456.789. We don't want to capture any values like 1.234 billion, so we need to add a negative lookahead group that looks ahead for \"million\" or \"billion\" after the number and rejects the match if it finds those strings. Don't forget the space! The new form should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580e758-27b2-4b6e-bd37-1a8a236c5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0f2a8-1d1f-4955-885d-6c1d1b9647da",
   "metadata": {},
   "source": [
    "Some values are given as a range.\n",
    "To solve this problem, we'll search for any string that starts with a dollar sign and ends with a hyphen, and then replace it with just a dollar sign using the replace() method. The first argument in the replace() method is the substring that will be replaced, and the second argument in the replace() method is the string to replace it with. We can use regular expressions in the first argument by sending the parameter regex=True, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b494a-62e5-4530-bb28-06cb8ce9911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba337438-89c7-4fe1-85b9-a794141c66dc",
   "metadata": {},
   "source": [
    "Extract and Convert the Box Office Values\n",
    "Now that we've got expressions to match almost all the box office values, we'll use them to extract only the parts of the strings that match. We do this with the str.extract() method. This method also takes in a regular expression string, but it returns a DataFrame where every column is the data that matches a capture group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59957937-73d6-4313-b01c-5550ed960211",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office.str.extract(f'({form_one}|{form_two})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b263307-34db-48f1-8761-6c0de3546940",
   "metadata": {},
   "source": [
    "Now we need a function to turn the extracted values into a numeric value. We'll call it parse_dollars, and parse_dollars will take in a string and return a floating-point number. We'll start by making a skeleton function with comments explaining each step, and then fill in the steps with actual code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb45df-c453-496b-871f-81059b426dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dollars(s):\n",
    "    # if s is not a string, return NaN\n",
    "    if type(s) != str:\n",
    "        return np.nan\n",
    "\n",
    "    # if input is of the form $###.# million\n",
    "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" million\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a million\n",
    "        value = float(s) * 10**6\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###.# billion\n",
    "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" billion\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a billion\n",
    "        value = float(s) * 10**9\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###,###,###\n",
    "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and commas\n",
    "        s = re.sub('\\$|,','', s)\n",
    "\n",
    "        # convert to float\n",
    "        value = float(s)\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # otherwise, return NaN\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822686b7-d55e-488f-b9db-d03ae52ccd20",
   "metadata": {},
   "source": [
    "Now we have everything we need to parse the box office values to numeric values.\n",
    "\n",
    "First, we need to extract the values from box_office using str.extract. Then we'll apply parse_dollars to the first column in the DataFrame returned by str.extract, which in code looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525e8eb-51d2-41be-827c-2c2ac8ff08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a0095-ae38-4db6-9d2d-a6a48f1d8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['box_office']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c140f40f-e44a-475d-ba3f-1dc1c01d51ca",
   "metadata": {},
   "source": [
    "We no longer need the Box Office column, so we'll just drop it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec6e11-78f6-4874-ac59-204730d2ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.drop('Box office', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908ead7-2e40-4915-a880-6798133211e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a budget variable with the following code:\n",
    "\n",
    "budget = wiki_movies_df['Budget'].dropna()\n",
    "\n",
    "\n",
    "#Convert any lists to strings:\n",
    "\n",
    "budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "#Then remove any values between a dollar sign and a hyphen (for budgets given in ranges):\n",
    "\n",
    "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291175b-fc76-4478-a066-256fb9cacbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
    "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
    "budget[~matches_form_one & ~matches_form_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1ecf7-a83f-4f8a-86cc-e205293fc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "budget[~matches_form_one & ~matches_form_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2969fd-2790-44e5-9e93-a55138261906",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f773712-9a2c-474a-9504-f98aca632a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.drop('Budget', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b2969-f985-4821-918d-c023ab7a963f",
   "metadata": {},
   "source": [
    "Parse Release Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e480a83-6e8d-434f-a039-25de0366e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb749a-5d64-428f-aa69-e91624495e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date.tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775f242-4f01-4b8a-813b-ac6387c6ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]?\\d,\\s\\d{4}'\n",
    "date_form_two = r'\\d{4}.[01]\\d.[0123]\\d'\n",
    "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "date_form_four = r'\\d{4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1deb94-33a7-4f8e-8b20-a80fef86f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284089ba-5f76-4dd5-948e-851399b788f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515db9e-6b23-445f-9ff8-aa880e9eccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35c232-031d-4523-bbc5-b2bafb1a320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7519e-927d-47e8-b28a-8f19a6daedac",
   "metadata": {},
   "source": [
    "Parse Running Time\n",
    "make a variable that holds the non-null values of Release date in the DataFrame, converting lists to strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c2037-ef69-4c8e-9b7d-587a3e6384b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac398ff-58db-41a5-88f8-e9aee5a2281c",
   "metadata": {},
   "source": [
    "It looks like most of the entries just look like \"100 minutes.\" Let's see how many running times look exactly like that by using string boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633dda4-6be0-42a6-9dce-6a74caaedda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f91d2e-020e-47c7-8bbe-4cd371258701",
   "metadata": {},
   "source": [
    "The above code returns 6,528 entries. Let's get a sense of what the other 366 entries look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f03b24-9e76-472d-a054-cfa9f6371e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time[running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False) != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6bf8a4-3a00-4c47-95f5-2b0545a785ef",
   "metadata": {},
   "source": [
    "Let's make this more general by only marking the beginning of the string, and accepting other abbreviations of \"minutes\" by only searching up to the letter \"m.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd079407-f7d5-40b3-b4bf-e1866e8a72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1fe353-fb0b-42fd-b2e1-5bc317772fb0",
   "metadata": {},
   "source": [
    "That accounts for 6,877 entries. The remaining 17 follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef6bab-8ae5-4c79-8ce1-09631607f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time[running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea55a1-de4d-4e03-a8fb-3ae32f039a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558ff26-b0e1-437c-8b3d-144288866a2c",
   "metadata": {},
   "source": [
    "Unfortunately, this new DataFrame is all strings, we'll need to convert them to numeric values. Because we may have captured empty strings, we'll use the to_numeric() method and set the errors argument to 'coerce'. Coercing the errors will turn the empty strings into Not a Number (NaN), then we can use fillna() to change all the NaNs to zeros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bc04d-c64b-4cf3-ba0a-9c0f42567b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21c2f0-3a96-4954-8e41-a231b02a9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_time_extract.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcccc6f-b4d9-441e-8a47-564141503a18",
   "metadata": {},
   "source": [
    "Now we can apply a function that will convert the hour capture groups and minute capture groups to minutes if the pure minutes capture group is zero, and save the output to wiki_movies_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370073c4-4267-472b-86af-5bac9b2880de",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f28952-2b48-45d8-83db-407bceaf4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.drop('Running time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa15e49-246f-44f1-8364-fdd00800dc41",
   "metadata": {},
   "source": [
    "Clean up the Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50700e-ece7-4a68-b0c8-1ca2102854fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f2e21-f7c7-467f-8248-0dd870057b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata['adult'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2645d8-47cf-48c8-b0c7-05d6831b78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca03bbf-46a9-4561-9924-f91805186c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata['video'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f6aa2-48f6-4f62-aef3-1de8b41a76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata['video'] == 'True'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61485df-e45e-4cf3-a3e6-cc7583b17501",
   "metadata": {},
   "source": [
    "For the numeric columns, we can just use the to_numeric() method from Pandas. We'll make sure the errors= argument is set to 'raise', so we'll know if there's any data that can't be converted to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc24358-a83e-481f-b2a2-1c505a861c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993db652-45ef-46c2-9b82-fbea5ae1b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec13c328-151e-4cd6-b88a-1f79b431c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfc9ac-8a0f-4dff-95a3-3209904f156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717b76a-7d83-4f0a-933e-f438392fb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979bbaa-2905-433f-9a02-925a63712258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(ratings['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70081668-7338-4345-9857-b833d63774f5",
   "metadata": {},
   "source": [
    "These dates don't seem outlandish—the years are within expected bounds, and there appears to be some consistency from one entry to the next. Since the output looks reasonable, assign it to the timestamp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f974d-b74c-43ef-9542-229720edf9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4a962-835e-4797-bd6f-8dd4a3942999",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7ce2d-c763-40f8-bfbd-8d152e61ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "ratings['rating'].plot(kind='hist')\n",
    "ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53953c81-e5ca-496b-9c1a-09d2a4177e30",
   "metadata": {},
   "source": [
    "Now that the Wikipedia data and Kaggle data are cleaned up and in tabular formats with the right data types for each column, Britta can join them together. However, after they're joined, the data still needs to be cleaned up a bit, especially where Kaggle and Wikipedia data overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9d621-7cda-497e-a2ba-39b832f6cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d623537-6bb7-45f7-93e7-fdb6ea05b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4783e-a025-45f7-a5b8-97d33d6a46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competing data:\n",
    "# Wiki                     Movielens                Resolution\n",
    "#--------------------------------------------------------------------------\n",
    "# title_wiki               title_kaggle              drop Wikipedia\n",
    "# running_time             runtime                   Keep Kaggle; fill in zeros with Wikipedia data.\n",
    "# budget_wiki              budget_kaggle             Keep Kaggle; fill in zeros with Wikipedia data.\n",
    "# box_office               revenue                   Keep Kaggle; fill in zeros with Wikipedia data.\n",
    "# release_date_wiki        release_date_kaggle       Drop Wikipedia.\n",
    "# Language                 original_language         Drop Wikipedia.\n",
    "# Production company(s)    production_companies      \tDrop Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d860a44-7827-4426-9f82-c9c54d236b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1349fb9a-8fbb-4c54-b349-f13bd6c0fead",
   "metadata": {},
   "source": [
    "movies_df[['title_wiki','title_kaggle']]\n",
    "\n",
    "They both seem pretty consistent, which we'd expect. Look at the rows where the titles don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268417e3-0c3a-4c6c-9b2d-512925b8bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['title_wiki'] != movies_df['title_kaggle']][['title_wiki','title_kaggle']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3a67a-e547-4668-8d7e-76d0003ea40a",
   "metadata": {},
   "source": [
    "Both options look pretty good, but the Kaggle data looks just a little bit more consistent. Let's confirm there aren't any missing titles in the Kaggle data with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8cda6f-50fa-4cb3-a4f8-01002d15ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show any rows where title_kaggle is empty\n",
    "movies_df[(movies_df['title_kaggle'] == '') | (movies_df['title_kaggle'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91991a5-2655-418b-9cbc-24a2980441a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['running_time','runtime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101758e7-2651-4e64-ac57-38fa48464829",
   "metadata": {},
   "source": [
    "A scatter plot is a great way to give us a sense of how similar the columns are to each other. If the two columns were exactly the same, we'd see a scatter plot of a perfectly straight line. Any wildly different values will show up as dots far from that central line, and if one column is missing data, those values will fall on the x-axis or y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f90679-89d6-4d7e-8fb9-f813d7f51f3c",
   "metadata": {},
   "source": [
    "ecause we're dealing with merged data, we should expect there to be missing values. Scatter plots won't show null values, so we need to fill them in with zeros when we're making our plots to get the whole picture.\n",
    "\n",
    "The following code will fill in missing values with zero and make the scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c501c-fe45-4008-a056-a0c33c63ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.fillna(0).plot(x='running_time', y='runtime', kind='scatter') #y axis is kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe9328a-2c87-4404-a0d3-98f45831a166",
   "metadata": {},
   "source": [
    "Notice that there are more data points on the origin of the Y axis than on the origin of the X axis. Since the X axis is Wikipedia and the Y axis is Kaggle, this means there are more missing entries in the Wikipedia data set than in the Kaggle data set. Also, most of the runtimes are pretty close to each other but the Wikipedia data has some outliers, so the Kaggle data is probably a better choice here. However, we can also see from the scatter plot that there are movies where Kaggle has 0 for the runtime but Wikipedia has data, so we'll fill in the gaps with Wikipedia data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1039109-3bc4-4da7-98dd-3aab001e2fe0",
   "metadata": {},
   "source": [
    "Since budget_wiki and budget_kaggle are numeric, we'll make another scatter plot to compare the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c4e16-6535-4278-a6cb-509c5649a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.fillna(0).plot(x='budget_wiki',y='budget_kaggle', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2520e15-fe8f-4735-95e3-0d3958b6f829",
   "metadata": {},
   "source": [
    "The box_office and revenue columns are numeric, so we'll make another scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d2fd6-dbc5-4c6d-8ef1-7e43df7d7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.fillna(0).plot(x='box_office', y='revenue', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83dbc65-730f-4b1e-bce4-7d5c84afdff0",
   "metadata": {},
   "source": [
    "That looks pretty close, but we might be getting thrown off by the scale of that large data point. Let's look at the scatter plot for everything less than $1 billion in box_office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ca88f-0537-4768-a9b8-8c8808c1d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.fillna(0)[movies_df['box_office'] < 10**9].plot(x='box_office', y='revenue', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564b8a7-454e-41f6-9272-ba39f176da94",
   "metadata": {},
   "source": [
    "For release_date_wiki and release_date_kaggle, we can't directly make a scatter plot, because the scatter plot only works on numeric data. However, there's a tricky workaround that we can use. We'll use the regular line plot (which can plot date data), and change the style to only put dots by adding style='.' to the plot() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ced17-4535-4558-9376-0b5f65216976",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['release_date_wiki','release_date_kaggle']].plot(x='release_date_wiki', y='release_date_kaggle', style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb01d86-1fd7-4bfb-a7ad-5cffc3dc32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['release_date_wiki','release_date_kaggle']].plot(x='release_date_wiki', y='release_date_kaggle', style='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c007235-ede7-456f-b1ce-56f3acbe0b6b",
   "metadata": {},
   "source": [
    "Based on the output, it looks like somehow The Holiday in the Wikipedia data got merged with From Here to Eternity. We'll have to drop that row from our DataFrame. We'll get the index of that row with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270234ae-bbe0-4841-858d-01896024c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e0987-4c29-4e41-8edc-aaca8cd1e2c3",
   "metadata": {},
   "source": [
    "Then we can drop that row like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7eff6f-7bb6-42c2-8b5a-d8e7cebce3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.drop(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e839a-fb9c-4c0b-b610-81b54b37f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['release_date_wiki'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14fd91-ed93-46f8-9efa-356435d81eb8",
   "metadata": {},
   "source": [
    "For the language data, we'll compare the value counts of each. However, consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e9736-5650-4338-affd-bf18f296421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['Language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f19eb-c0d9-478f-a8f7-8ba03bab0247",
   "metadata": {},
   "source": [
    "This code throws an error because some of the language data points are stored as lists.\n",
    "We need to convert the lists in Language to tuples so that the value_counts() method will work. See the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327264f-a848-4e5f-93a8-106e3a0d485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['Language'].apply(lambda x: tuple(x) if type(x) == list else x).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b653b7-2e57-4c52-88ee-1381e68dc3f2",
   "metadata": {},
   "source": [
    "For the Kaggle data, there are no lists, so we can just run value_counts() on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b5dbe-ad98-4145-aef4-f8afccb6f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['original_language'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a4021-81cd-415f-91d8-ebfbbf0d7949",
   "metadata": {},
   "source": [
    "Again, we'll start off just taking a look at a small number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875218b2-2dd0-4fe2-8961-d131221800a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['Production company(s)','production_companies']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e10f0-b75b-4aff-9230-8ee28f8a20a6",
   "metadata": {},
   "source": [
    "First, we'll drop the title_wiki, release_date_wiki, Language, and Production company(s) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125bd208-2fde-42ce-bd0f-996401e52ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cf220-a667-47f5-ae45-ab1e5a77df7a",
   "metadata": {},
   "source": [
    "Next, to save a little time, we'll make a function that fills in missing data for a column pair and then drops the redundant column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7e920-20a9-43bb-b339-a866d0fa70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "    df[kaggle_column] = df.apply(\n",
    "        lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "        , axis=1)\n",
    "    df.drop(columns=wiki_column, inplace=True)\n",
    "    \n",
    "    \n",
    "fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "movies_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf4987-d144-4ede-a1c5-c95080190d22",
   "metadata": {},
   "source": [
    "Now we can run the function for the three column pairs that we decided to fill in zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec363766-39c1-4b60-b77a-12f4f9d7da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in movies_df.columns:\n",
    "    lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "    value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "    num_values = len(value_counts)\n",
    "    if num_values == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5d333-fac9-40ef-9771-b5d9c3cd8c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49e5f8-c299-49fb-a124-bbaeb92234d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['video'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8b6ed-c58e-4c3f-a0a3-740f8bb99482",
   "metadata": {},
   "source": [
    "The following code is one way to reorder the columns:\n",
    "If you did not use .loc to reorder the columns and instead passed a list of column names to the indexing operator (i.e. movies_df = movies_df[[‘imdb_id’, ‘title_kaggle’, … ]]), you may receive a SettingWithCopyWarning. Don't panic! This isn't an error, so your code will continue to work, but it is a warning that your code may not behave as you expect. In this case, your code will work fine, but for best practices, use .loc instead to avoid this warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bfd6d1-e46d-4075-90fb-dfddc5f95360",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                       'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                       'genres','original_language','overview','spoken_languages','Country',\n",
    "                       'production_companies','production_countries','Distributor',\n",
    "                       'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                      ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7565a81a-8091-48e1-ab7c-194da95fbea0",
   "metadata": {},
   "source": [
    "Finally, we need to rename the columns to be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8418f10-027d-4db8-9880-ef79a7dd36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.rename({'id':'kaggle_id',\n",
    "                  'title_kaggle':'title',\n",
    "                  'url':'wikipedia_url',\n",
    "                  'budget_kaggle':'budget',\n",
    "                  'release_date_kaggle':'release_date',\n",
    "                  'Country':'country',\n",
    "                  'Distributor':'distributor',\n",
    "                  'Producer(s)':'producers',\n",
    "                  'Director':'director',\n",
    "                  'Starring':'starring',\n",
    "                  'Cinematography':'cinematography',\n",
    "                  'Editor(s)':'editors',\n",
    "                  'Writer(s)':'writers',\n",
    "                  'Composer(s)':'composers',\n",
    "                  'Based on':'based_on'\n",
    "                 }, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3805b-b412-43e0-a53b-7fe2f65ac87b",
   "metadata": {},
   "source": [
    "count given rating, First, we need to use a groupby on the \"movieId\" and \"rating\" columns and take the count for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524be44-9f10-462d-8a46-1f701949023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count()\n",
    "rating_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35126257-fdc6-4b92-bf10-f4b1cc24661d",
   "metadata": {},
   "source": [
    "Then we'll rename the \"userId\" column to \"count.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c04d49-d49a-464e-af09-e6e8926a782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                .rename({'userId':'count'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73086b18-3667-4eec-ad00-5cd001a27e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e62d44f-e35b-4643-8077-e6a809609980",
   "metadata": {},
   "source": [
    "We can pivot this data so that movieId is the index, the columns will be all the rating values, and the rows will be the counts for each rating value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df6c3b-4f50-4d11-a2be-833b547881e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                .rename({'userId':'count'}, axis=1) \\\n",
    "                .pivot(index='movieId',columns='rating', values='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b47f6-fcc4-4932-a988-c8320f854f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3ea97-5b1d-4ee5-b494-4e877b918610",
   "metadata": {},
   "source": [
    "We want to rename the columns so they're easier to understand. We'll prepend rating_ to each column with a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fa1eb-cd0f-4b11-82c5-d4358d517a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024594ba-0ea4-403a-856a-efca9bd3b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96305f-14e1-492c-aecf-c98c6164b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c7c93-e35e-4c72-b664-10e72dc690f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9bbf4-c368-4c3b-9f5c-c933eebfaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e416be-a977-41a5-939e-3a135e485774",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9e6a7-fcd6-4c59-9260-e7e77eafbeef",
   "metadata": {},
   "source": [
    "The database engine needs to know how to connect to the database. To do that, we make a connection string. For PostgreSQL, the connection string will look like the following:\n",
    "\n",
    "\"postgresql://[user]:[password]@[location]:[port]/[database]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4225bb-508a-48d1-9594-c3c4051a3620",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/movie_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e6bf1-9b7e-4320-ab15-90fbd5ada897",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce628bb-c96c-4c45-ad1a-e9c9c67e8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.to_sql(name='movies',con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5417ace-f692-4645-9f3c-a91f822778b4",
   "metadata": {},
   "source": [
    "# create a variable for the number of rows imported\n",
    "rows_imported = 0\n",
    "for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "    # print out the range of rows that are being imported\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "    # increment the number of rows imported by the size of 'data'\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    # print that the rows have finished importing\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc2350-6252-4b08-b30d-8966c8b94b5a",
   "metadata": {},
   "source": [
    "rows_imported = 0\n",
    "for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    print(f'Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca9750-f459-437d-b0b6-0359edc95ec3",
   "metadata": {},
   "source": [
    "adding in runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810a60f-7e3d-4b0d-a883-7dfde9004660",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_imported = 0\n",
    "# get the start_time from time.time()\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    # add elapsed time to final print out\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566a9a0-5f29-447a-899c-2f775a6ef49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
